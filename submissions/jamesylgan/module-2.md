For the Module 2 exercise, I will be analysing the community AgnosticTalk, which I have managed since around 2009.

> If it is a community you manage, you can analyse one of your own past moderation actions, in light of the contents of this module.

> Some prompts may be:

> - Did I use the right tool to resolve this conflict?

> - Was the outcome the outcome I wanted?

> - What could have improved the outcome?

### Nature of the incident

> Tell us about what happened that required moderation?

I will compare two different types of incidents that happen on a regular basis. The nature of the online community I manage is the discussion of religious philosophy. In society, and on the internet especially, religion is quite a contraversial subject. We often receive comments from particularly peious followers of religion. They can range from misunderstanding of our Code Of Conduct, to malicious and targeted harassment. **One example** is a user who will post and comment a few times about how Christianity is the only true religion - something that we urge users to avoid doing, emphasizing discussion of philosophical ideas instead. **On the other hand**, are users who post and comment calling other users immoral for following other religions, and criticizing support of gay marriage and abortion.

### Moderation action

> How did the moderators resolve the situation? What techniques did they use? Did they use any moderation tools? How did the capabilities of their platform influence their moderation decisions?

We would resolve the situations differently. For the **first example**, we would **message the user** and inform them of our **Code Of Conduct** and stress that discussing ideas was more beneficial: not only would they abide by our rules, but they would have a better chance of convincing others of their viewpoint (or, from our perspective, contributing positively to our community as a place to teach and learn about religion). In the cases where they would not cease evangelism, we would issue a **temporary suspension/ban**.

In the **second example**, we found that these types of users did not change their behavior. Depending on the severity of the incident, we would **send a similar message to the user**, possibly alongside a **temporary suspension/ban**. If the user continued such action, we would **suspend or ban them for a longer period of time**, possibly **permanently or through an IP ban**.

Our platform was a phpBB forum, which allowed us to ban IPs - this helped to keep toxic users away from our website. We also haev an accompanying Facebook page, which was harder to moderate. In general, we would communicate through comment chains and issue bans with much less discretion due to our limitations to communicate privately and the speed at which incidents would escalate on that platform.

### Outcome

> What was the outcome of their moderation action? Was it positive for the community?

The outcome of our moderation actions were generally the most positive we could achieve. Many users that we initially warned **for the first example** would become regular contributors to our community and abide by our Code of Conduct fully. **For the second example**, we typically found that even the ones we warned would eventually necessitate a permanent ban, and the most positive option was typically to moderate fairly harshly.

### What could be different?

> Based on what you've learnt in this module, and your analysis of this situation, what could have been done differently to improve the outcome.

We applied Conversational Aikido as best we can in the first example situations, and in the second example situations we acted roughly in line with the recommendation for how to deal with trolls; however, this experience has led me to deal harshly and independently with trolls, and I would aim to craft a message amongst trusted colleagues in the future before engaging trolls (as per Lee's post on how to deal with trolls). 

I would also aim to develop more comprehensive Codes of Conduct in future projects and communities, including the Contributor Covenant.
